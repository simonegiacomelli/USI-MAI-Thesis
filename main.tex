%v1.16

\documentclass[11pt, mscthesis]{usiinfthesis}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} % Output font encoding for international characters
\usepackage{svg}
\usepackage[english]{babel}
\usepackage{lipsum}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{subfig}
\lstset{columns=fixed, basicstyle=\ttfamily, basewidth=0.5em}

% \RequirePackage{scrhack} % Loads fixes for various packages

\graphicspath{{./images/}{./images2/}}
\DeclareGraphicsExtensions{*.svg,.png,.pdf}

\newcommand{\vect}[1]{\boldsymbol{#1}}
%%%%%
\makeatletter
\newcommand{\labeltextbf}[3][]{%
    \@bsphack%
    \csname phantomsection\endcsname% in case hyperref is used
    \def\tst{#1}%
    \def\labelmarkup{\textbf}% How to markup the label itself
    %\def\refmarkup{\labelmarkup}% How to markup the reference
    \def\refmarkup{}%
    \ifx\tst\empty\def\@currentlabel{\refmarkup{#2}}{\label{#3}}%
    \else\def\@currentlabel{\refmarkup{#1}}{\label{#3}}\fi%
    \@esphack%
    \labelmarkup{#2}% visible printed text.
}
\makeatother

%%%%%
\lstdefinelanguage{algebra}
{morekeywords={import,sort,constructors,observers,transformers,axioms,if,
else,end},
sensitive=false,
morecomment=[l]{//s},
}
\DeclareUnicodeCharacter{0301}{*************************************}


\usepackage{subfiles}
\usepackage{biblatex}
\addbibresource{biblio.bib}

\title{Using Deep Learning to Identify Technical Debt} %compulsory
\specialization{Major in Artificial Intelligence}%optional
\subtitle{Levereging Self Admitted Technical Debt} %optional 
\author{Simone Giacomelli} %compulsory
\begin{committee}
\advisor{Prof. Dr.}{Gabriele Bavota}{} %compulsory
\coadvisor{Dr.}{Csaba Nagy}{}{} %optional
\end{committee}
\Day{1} %compulsory
\Month{January} %compulsory
\Year{2021} %compulsory, put only the year
\place{Lugano} %compulsory

\dedication{To the part of you that will always\\learn new things and strive to be better}

%\openepigraph{Someone said \dots}{Someone} %optional

%\makeindex %optional, also comment out \theindex at the end

\begin{document}

\maketitle %generates the titlepage, this is FIXED

\frontmatter %generates the frontmatter, this is FIXED

\begin{abstract}
% Composed of four parts: \\
% a: context\\
% b: problem\\
% c: proposed solution\\
% d: results\\
% \\
% max 400 words.
The `technical debt' metaphor describes a misalignment between the appropriate solution to a problem and the non-optimal actual implementation. Software developers accumulate technical debt when they choose speed at the expense of quality and correctness. As the debt metaphor suggests, there are multiple elements involved; two of them are: gain and interest. The gain is a shorter time to market and lower initial costs. The interest is all the additional effort caused by choosing the easy but limited solution, i.e. it's harder to make changes on suboptimal code implementation. When the debt is not paid in a timely manner the interest can crush the evolution capabilities of the project itself. Researchers agree that it's important to track, manage and repay technical debt to avoid dire consequences.

Developers, while introducing technical debt, can decide to leave a source code comment to document what they are doing; this is called self-admitted technical debt (SATD). A SATD is an acknowledgement that something needs to be fixed.

In this thesis we propose a technical debt classifier fueled by the SATD harvested from 245,243 GitHub Java projects. We detail the process of the creation of the dataset. We explain how to extract features from a source snippet; these features are learned by the network and, also using an attention mechanism, encoded in a fixed-length vector. The last layer of the deep learning model finally classifies the snippet as TD-free or TD-affected.  

In this empirical study we assess, using quantitative and qualitative research, the accuracy of the classifier and analyze how the prediction confidence influences it.

The results on multiple datasets show a precision ranging between 67\% and 71\%, and a F1-score between 61\% and 66\%. Our quantitative analysis on the prediction confidence score shows that we can significantly increase the precision at the expanse of lowering the recall. 
We explore quantitative and qualitative findings in both correct and incorrect predictions; we show patterns successfully learned by the network (empty exception block, magic constant and return null) and we also show why specific predictions fail.


% The results on the confidence level analysis show interesting results: when filtering for a confidence level greater than 0.9 we measured a gain on precision, from 71\% to 78\%; the excluded samples shows their effect also on the recall that goes from 62\% down to 52\%. When using a dataset with bigger code snippets and confidence greater than 0.9 we discard 98\% of the test predictions; however the precision is high as 99\% and the recall drops to 10\%, both due to the (correct and incorrect) discarded predictions.


\end{abstract}


\begin{acknowledgements}
I would like to thank my advisors Prof. Dr. Gabriele Bavota and Dr. Csaba Nagy. They helped me more than they can imagine. Their insightful comments and professionalism contributed immensely to make this thesis an amazing and rewarding project.
\\
\\
A huge thanks to all the people that make my university tick. I'm grateful to all the staff of Universit\`a della Svizzera Italiana, you inspired me on the journey that led me to join the Academic Senate and the Council of the Faculty of Informatics as student representatives. I want to thank the rector, Boas Erez, he was one of the people who initially inspired me to come to USI (through the XXI Dies academicus youtube video). I also want to thank Antonio Carzaniga, Kai Hormann, Luca Maria Gambardella, Marc Langheinrich, Silvia Santini, Gabriele Balbi, Barbara Antonioli Mantegazzini, Hauswirth Matthias, Monica Landoni, Piotr Krzysztof Didyk, Alessandro Giusti, Evanthia Papadopoulou, Giovanni Boracchi, Giovanni Zavaritt, Nina Caggi, Elisa Larghi, Jacinta Vigini Barth, Nadia Ruggiero-Ciresa, Cristina Largader, Daniela Mondini, Patrick Gagliardini and Umberto Bondi; you all helped me one way or another. A big thank you to the Precrime team, Paolo, Andrea, Gunel, Vincenzo, Nargiz and Michael, you made me feel at home and I’m very grateful for it. A special thanks goes to Robin Creti for his amazing work on the Student Corporation, it’s a great thing for all USI students.

I met wonderful people and you all made it an invaluable learning experience. You will always have a special place in my heart. USI is young and beautiful but you are the reason why it’s a great and inspiring university.
\\
\\
I would like to thank my family. A special thanks to my sister Daria, always present, and to Claudio, Nicola, my dad and Carla. I also want to send my love to my mum; she is probably the force and reason I began my university studies. A big thanks to my cousin Luca, our childhood together meant everything to me. I also want to thank my dear aunt Anna Grazia, always helpful and encouraging. A huge thanks to Massimo and Tina for their support and love. Pippo and Pg, I finally made it! Thank you for your everlasting example. 
\\
\\
I have many friends that I want to thank. Thank you Emilio, for your friendship, honesty and valuable feedback. Thank you Beppe for your help when I was least expecting it. Thank you Alessio, Andrea and Marco, our `USI and abUSI' group is awesome! Thank you Lorenzo and Wei, our friendship and work together taught me more than I could ask for. Thank you Marco and Francesco for the good talks and sharing our life experiences.  I want to thank all friends I met at USI that I do not explicitly name here: thank you for your friendship and time spent in and out of the university; a bright and fulfilling future awaits you!
\\
\\
Finally, last but not least, I would like to thank all those people and events that hindered me and blatantly tried to discourage me. They are one of the many reasons I will persist, do better and finally succeed.


\end{acknowledgements}

\tableofcontents 
\listoffigures %optional
\listoftables %optional

\mainmatter

\input{1_intro}
\input{2_art}
\input{3_using}
\input{4_empirical}
\input{5_results}
\input{6_threats}
\input{7_conclusion}

%%%%%%% commented appendix

\appendix

\input{appendix}
% \appendix %optional, use only if you have an appendix
% \chapter{Some retarded material}
% \section{It's over\dots}
% \lipsum 

\nocite{*}
\backmatter

%%%%%%% commented glossary
%\chapter{Glossary} %optional

%\bibliographystyle{alpha}
%\bibliographystyle{dcu}
%\bibliographystyle{plainnat}
%\bibliography{biblio}



\printbibliography
%\cleardoublepage
%\theindex %optional, use only if you have an index, must use
%\makeindex in the preamble
\end{document}